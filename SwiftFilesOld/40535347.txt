CGImageCreateWithImageInRect subimages are zoomed and misplaced
I want to experiment with real-time filtering of subregions of the iphone camera feed. The idea is to display the filtered regions overlaid on the screen so I can see the filtering results in real-time as I move the camera. It seems it should be straightforward to extract frame subimages via CGImageCreateWithImageInRect and put them in UIImageViews. But the resulting images are zoomed and misplaced, and I'm lost as to why. Here's my app running. Note the subimages are zoomed and not aligned with the guide boxes I've looked through many, many posts and blogs, and the closest I've found to my problem is in this SO post: Cannot crop touched location with CGImageCreateWithImageInRect in swift But his solution relies on features of the UIImageView source, which the UIView and AVCaptureVideoPreviewLayer I'm using don't have. And it's not clear to me why this fix works even in his case. My code simply obtains the preview frames as pixel buffers via AVCaptureVideoDataOutputSampleBufferDelegate : captureOutput : didOutputSampleBuffer and converts them to CGImages for input to CGImageCreateWithImageInRect. For the rect parameters I use the guide boxes' UIView.frame members. Here's my app in IB. Each UIImageView is constrained to the same dimensions as its corresponding UIView (i.e. guide box). Here's the source: import UIKit import AVFoundation class ViewController: UIViewController, AVCaptureVideoDataOutputSampleBufferDelegate { @IBOutlet weak var previewView: UIView! @IBOutlet weak var dateTimeCapture: UIImageView! @IBOutlet weak var machineIDAmtTime: UIImageView! @IBOutlet weak var ticketID: UIImageView! @IBOutlet weak var dateTimeCaptureBox: UIView! @IBOutlet weak var machineIDAmtTimeCaptureBox: UIView! @IBOutlet weak var ticketIDCaptureBox: UIView! var convertCtx: CIContext? var captureSession: AVCaptureSession? var stillImageOutput: AVCaptureStillImageOutput? var previewLayer: AVCaptureVideoPreviewLayer? var overlayLayer: CALayer? override func viewDidLoad() { super.viewDidLoad() convertCtx = CIContext(options: nil) // Guide boxes are set to black in IB so I can see them // Clear them here dateTimeCaptureBox.backgroundColor = UIColor.clearColor() machineIDAmtTimeCaptureBox.backgroundColor = UIColor.clearColor() ticketIDCaptureBox.backgroundColor = UIColor.clearColor() // Set color to bright green and border to useful width dateTimeCaptureBox.layer.borderColor = UIColor.greenColor().CGColor dateTimeCaptureBox.layer.borderWidth = 5 machineIDAmtTimeCaptureBox.layer.borderColor = UIColor.greenColor().CGColor machineIDAmtTimeCaptureBox.layer.borderWidth = 5 ticketIDCaptureBox.layer.borderColor = UIColor.greenColor().CGColor ticketIDCaptureBox.layer.borderWidth = 5 } override func viewWillAppear(animated: Bool) { super.viewWillAppear(animated) captureSession = AVCaptureSession() captureSession!.sessionPreset = AVCaptureSessionPresetPhoto let backCamera = AVCaptureDevice.defaultDeviceWithMediaType(AVMediaTypeVideo) var error: NSError? var input: AVCaptureDeviceInput! do { input = try AVCaptureDeviceInput(device: backCamera) } catch let error1 as NSError { error = error1 input = nil } if error == nil && captureSession!.canAddInput(input) { captureSession!.addInput(input) stillImageOutput = AVCaptureStillImageOutput() stillImageOutput!.outputSettings = [AVVideoCodecKey: AVVideoCodecJPEG] if captureSession!.canAddOutput(stillImageOutput) { captureSession!.addOutput(stillImageOutput) previewLayer = AVCaptureVideoPreviewLayer(session: captureSession) previewLayer!.videoGravity = AVLayerVideoGravityResizeAspect previewLayer!.connection?.videoOrientation = AVCaptureVideoOrientation.Portrait previewView!.layer.addSublayer(previewLayer!) captureSession!.startRunning() } } let videoOutput = AVCaptureVideoDataOutput() videoOutput.setSampleBufferDelegate(self, queue: dispatch_get_main_queue()) if captureSession!.canAddOutput(videoOutput) { captureSession!.addOutput(videoOutput) videoOutput.connectionWithMediaType(AVMediaTypeVideo).videoOrientation = AVCaptureVideoOrientation.Portrait videoOutput.connectionWithMediaType(AVMediaTypeVideo).videoScaleAndCropFactor = 1.0 } } override func viewDidAppear(animated: Bool) { super.viewDidAppear(animated) previewLayer!.frame = previewView.bounds } func captureOutput(captureOutput: AVCaptureOutput!, didOutputSampleBuffer sampleBuffer: CMSampleBuffer!, fromConnection connection: AVCaptureConnection!) { // 1. get image data from CMSampleBuffer into a CVPixelBuffer let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) // 2. Get a CIImage from which we can get a CGImage // which we need in order to extract a rectangular subimage // via CGImageCreateWithImageInRect let cameraCIImage = CIImage(CVPixelBuffer: pixelBuffer!) // 3. Get a the CGImage let cameraCGImage = convertCIImageToCGImage(cameraCIImage) self.dateTimeCapture.image = UIImage(CGImage: CGImageCreateWithImageInRect(cameraCGImage, dateTimeCaptureBox.frame)!) self.machineIDAmtTime.image = UIImage(CGImage: CGImageCreateWithImageInRect(cameraCGImage, machineIDAmtTimeCaptureBox.frame)!) self.ticketID.image = UIImage(CGImage: CGImageCreateWithImageInRect(cameraCGImage, ticketIDCaptureBox.frame)!) } func convertCIImageToCGImage(inputImage: CIImage) -> CGImage! { return convertCtx!.createCGImage(inputImage, fromRect: inputImage.extent) } func captureOutput(captureOutput: AVCaptureOutput!, didDropSampleBuffer sampleBuffer: CMSampleBuffer!, fromConnection connection: AVCaptureConnection!) { // print("Drop") } }