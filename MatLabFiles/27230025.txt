Improve naive gauss elimination, when zero elements are known
<p>I wrote naive gauss elimination without pivoting:</p> <pre><code>function [x] = NaiveGaussianElimination(A, b) N = length(b); x = zeros(N,1); mulDivOp = 0; subAddOp = 0; for column=1:(N-1) for row = (column+1):N mul = A(row,column)/A(column,column); A(row,:) = A(row,:)-mul*A(column,:); b(row) = b(row)-mul*b(column); mulDivOp = mulDivOp+N-column+2; subAddOp = subAddOp +N-column+1; end end for row=N:-1:1 x(row) = b(row); for i=(row+1):N x(row) = x(row)-A(row,i)*x(i); end x(row) = x(row)/A(row,row); mulDivOp = mulDivOp + N-row + 1; subAddOp = subAddOp + N-row; end x = x'; mulDivOp subAddOp return end </code></pre> <p>but I am curious if I can reduce the number of multiplications/divisions and additions/subtractions in case I know which elements of matrix are 0:</p> <p>For N = 10:</p> <pre><code>A = 96 118 0 0 0 0 0 0 0 63 154 -31 -258 0 0 0 0 0 0 0 0 -168 257 -216 0 0 0 0 0 0 0 0 202 24 308 0 0 0 0 0 0 0 0 -262 -36 -244 0 0 0 0 0 0 0 0 287 -308 171 0 0 0 0 0 0 0 0 197 229 -258 0 0 0 0 0 0 0 0 -62 -149 186 0 0 0 0 0 0 0 0 -43 255 -198 -147 0 0 0 0 0 0 0 -147 -220 </code></pre> <p>(non-zero values are from randi). In general, non-zero elements are a_{1, N}, a_{N,1} and a_{i,j} when abs(i-j) &lt;= 1. </p>
<p>Probably not. There are nice algorithms for reducing tridiagonal matrices (which these aren't, but they are close) to diagonal matrices. Indeed, this is one way in which the SVD of a matrix is produced, using orthogonal similarity transformations, not Gaussian elimination. </p> <p>The problem is that when you use Gaussian elimination to remove the nonzero entries in the first column, you will have introduced additional nonzero entries in the other columns. The further you proceed, the more you destroy the structure of the matrix. It may be that Gaussian elimination is simply the wrong approach for the problem you are trying to solve, at least if you are trying to exploit the structure of the matrix.</p>