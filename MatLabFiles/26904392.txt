How to vectorize finding the closest point out of a vector
<pre><code>BigList = rand(20, 3) LittleList = rand(5, 3) </code></pre> <p>I'd like to find for each row in the big list the 'closest' row in the little list, as defined by the euclidean norm (i.e. sum of squared distances between the corresponding values in the k=3 dimension).</p> <p>I can see how to do this using two loops, but it seems like there ought to be a better way to do this using built in matrix operations.</p>
<p>You can do it with <a href="http://es.mathworks.com/help/matlab/ref/bsxfun.html" rel="nofollow"><code>bsxfun</code></a>:</p> <pre><code>d = squeeze(sum((bsxfun(@minus, BigList, permute(LittleList, [3 2 1]))).^2, 2)); [~, ind] = min(d,[],2); </code></pre>
<p>The proper way is of course using <a href="http://www.mathworks.com/help/stats/nearest-neighbors.html" rel="nofollow">nearest-neighbor searching algorithms</a>.<br> However, if your dimension is not too high and your data sets are not big than you can simply use <a href="/questions/tagged/bsxfun" class="post-tag" title="show questions tagged 'bsxfun'" rel="tag">bsxfun</a>:</p> <pre><code>d = bsxfun( @minus, permute( bigList, [1 3 2] ), permute( littleList, [3 1 2] ) ); %//diff in third dimension d = sum( d.^2, 3 ); %// sq euclidean distance [minDist minIdx] = min( d, [], 2 ); </code></pre> <hr> <p>In addition to Matrix multiplication approach proposed <a href="http://stackoverflow.com/a/23911671/3293881">here</a>, there is another matrix multiplication without loops</p> <pre><code>nb = sum( bigList.^2, 2 ); %// norm of bigList's items nl = sum( littleList.^2, 2 ); %// norm of littleList's items d = bsxfun( @sum, nb, nl.' ) - 2 * bigList * littleList'; %// all the distances </code></pre> <p>The observation behind this method is that for Euclidean distance (L2-norm)</p> <pre><code>|| a - b ||^2 = ||a||^2 + ||b||^2 - 2&lt;a,b&gt; </code></pre> <p>With <code>&lt;a,b&gt;</code> being the dot product of the two vectors.</p>
<h2>Approach #1</h2> <p>There is a built in MATLAB function <strong><a href="http://in.mathworks.com/help/stats/pdist2.html" rel="nofollow"><code>pdist2</code></a></strong> which finds <code>"Pairwise distance between two sets of observations"</code>. With it, you can calculate the euclidean distance matrix and then find indices of minimum values along the appropriate dimension in the distance matrix that would represent the "closest" for each row of <code>bigList</code> in <code>littleList</code>.</p> <p>Here's the one-liner with it -</p> <pre><code>[~,minIdx] = min(pdist2(bigList,littleList),[],2); %// minIdx is what you are after </code></pre> <h2>Approach #2</h2> <p>If you care about performance, here's a method that leverages <a href="http://stackoverflow.com/questions/6058139/why-is-matlab-so-fast-in-matrix-multiplication"><strong><code>fast matrix multiplication in MATLAB</code></strong></a> and most of the code presented here is taken from <a href="http://stackoverflow.com/a/23911671/3293881">this smart solution</a>.</p> <pre><code>dim = 3; numA = size(bigList,1); numB = size(littleList,1); helpA = zeros(numA,3*dim); helpB = zeros(numB,3*dim); for idx = 1:dim helpA(:,3*idx-2:3*idx) = [ones(numA,1), -2*bigList(:,idx), bigList(:,idx).^2 ]; helpB(:,3*idx-2:3*idx) = [littleList(:,idx).^2 , littleList(:,idx), ones(numB,1)]; end [~,minIdx] = min(helpA * helpB',[],2); %//'# minIdx is what you are after </code></pre> <h2>Benchmarking</h2> <p>Benchmarking Code -</p> <pre><code>N1 = 1750; N2 = 4*N1; %/ datasize littleList = rand(N1, 3); bigList = rand(N2, 3); for k = 1:50000 tic(); elapsed = toc(); %// Warm up tic/toc end disp('------------- With squeeze + bsxfun + permute based approach [LuisMendo]') tic d = squeeze(sum((bsxfun(@minus, bigList, permute(littleList, [3 2 1]))).^2, 2)); [~, ind] = min(d,[],2); toc, clear d ind disp('------------- With double permutes + bsxfun based approach [Shai]') tic d = bsxfun( @minus, permute( bigList, [1 3 2] ), permute( littleList, [3 1 2] ) ); %//diff in third dimension d = sum( d.^2, 3 ); %// sq euclidean distance [~,minIdx] = min( d, [], 2 ); toc clear d minIdx disp('------------- With bsxfun + matrix-multiplication based approach [Shai]') tic nb = sum( bigList.^2, 2 ); %// norm of bigList's items nl = sum( littleList.^2, 2 ); %// norm of littleList's items d = bsxfun(@plus, nb, nl.' ) - 2 * bigList * littleList'; %// all the distances [~,minIdx] = min(d,[],2); toc, clear nb nl d minIdx disp('------------- With matrix multiplication based approach [Divakar]') tic dim = 3; numA = size(bigList,1); numB = size(littleList,1); helpA = zeros(numA,3*dim); helpB = zeros(numB,3*dim); for idx = 1:dim helpA(:,3*idx-2:3*idx) = [ones(numA,1), -2*bigList(:,idx), bigList(:,idx).^2 ]; helpB(:,3*idx-2:3*idx) = [littleList(:,idx).^2 , littleList(:,idx), ones(numB,1)]; end [~,minIdx] = min(helpA * helpB',[],2); toc, clear dim numA numB helpA helpB idx minIdx disp('------------- With pdist2 based approach [Divakar]') tic [~,minIdx] = min(pdist2(bigList,littleList),[],2); toc, clear minIdx </code></pre> <p>Benchmark results -</p> <pre><code>------------- With squeeze + bsxfun + permute based approach [LuisMendo] Elapsed time is 0.718529 seconds. ------------- With double permutes + bsxfun based approach [Shai] Elapsed time is 0.971690 seconds. ------------- With bsxfun + matrix-multiplication based approach [Shai] Elapsed time is 0.328442 seconds. ------------- With matrix multiplication based approach [Divakar] Elapsed time is 0.159092 seconds. ------------- With pdist2 based approach [Divakar] Elapsed time is 0.310850 seconds. </code></pre> <p><strong>Quick conclusions:</strong> The runtimes with Shai's second approach that was a combination of <code>bsxfun</code> and matrix multiplication were very close with the one based on <code>pdist2</code> and no clear winner could be decided between those two.</p>