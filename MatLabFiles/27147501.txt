Efficient way to store single matrices generated in a loop in Matlab?
<p>I would like to know whether there is a way to reduce the amount of memory used by the following piece of code in Matlab: </p> <pre><code>n=3; T=100; r=T*2; b=80; BS=1000 bsuppostmp_=cell(1,BS); bslowpostmp_=cell(1,BS); bsuppnegtmp_=cell(1,BS); bslownegtmp_=cell(1,BS); for w=1:BS bsuppostmp_{w}= randi([0,1],n*T,2^(n-1),r,b); bslowpostmp_{w}=randi([0,3],n*T,2^(n-1),r,b); bsuppnegtmp_{w}=randi([0,4],n*T,2^(n-1),r,b); bslownegtmp_{w}=randi([0,2],n*T,2^(n-1),r,b); end </code></pre> <p>I have decided to use cells of matrices because after this loop I need to call separately each single matrix in another loop.</p> <p>If I run this code I get the message error "Your system has run out of application memory".</p> <p>Do you know a more efficient (in terms of memory) way to store each single matrix?</p>
<p>Let's refer the page about <a href="http://fr.mathworks.com/help/matlab/matlab_prog/strategies-for-efficient-use-of-memory.html" rel="nofollow">Strategies for Efficient Use of Memory</a>:</p> <blockquote> <p>Because simple numeric arrays (comprising one mxArray) have the least overhead, you should use them wherever possible. When data is too complex to store in a simple array (or matrix), you can use other data structures.</p> <p>Cell arrays are comprised of separate mxArrays for each element. As a result, cell arrays with many small elements have a large overhead.</p> </blockquote> <p>I doubt that the overhead for cell array is really large ...</p> <p>Let me give a possible explanation. What if Matlab cannot use the swap file in case of storing the 4D arrays into a cell array? When storing large numeric arrays, there is no out-of-memory error because Matlab uses the swap file for caching each variable when the used memory becomes too big. Whereas if each 4D array is stored in a super cell array, Matlab sees it as a single variable and cannot fragment it part in the RAM and part in the swap file. Ok I don't work at Mathworks so I don't know if I'm right or not, it's just an idea about this topic so I would be glad to know what is the real reason.</p> <p>So my advice is the same as other comments: try to free matrices as soon as you've done with them. There is not so many possibilities to store many dense arrays: one big array (NOT recommended here, will reach out-of-memory sooner because Matlab makes it contiguous), cell array or struct array (and if I correctly understand the documentation, the overhead can be equivalent). In all cases, the data amount over all 4D arrays is really large, so the best thing to do is to care about keeping the memory constantly as low as possible by discarding some data once they are used and keep in memory only the results of computation (in case they take lower memory usage ...).</p>