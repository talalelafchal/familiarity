How to preallocate a list of external data structure in matlab?
<p>My problem is related to an <strong>externally defined data structure</strong>: tensor. Tensor is a multidimensional array. In the <a href="http://www.sandia.gov/~tgkolda/TensorToolbox/index-2.5.html" rel="nofollow">Matlab tensor toolbox 2.5</a>, tensor is a class with two fields: t.data, t.size:</p> <pre><code> % Create the tensor t.data = data; t.size = siz; t = class(t, 'tensor'); return; </code></pre> <p>Like the built-in function <code>zeros()</code> in Matlab, I can use <code>tenzeros()</code> , to create a tensor full of zeros, e.g., tenzeros([2,3,4]). There're also other types of tensor data structure in this toolbox: tensor, sptensor, ktensor, ttensor, etc.</p> <p><strong>My question is, how I can preallocate 200 of tenzeros or other tensor types, where each tensor is of the same size [100,200,300]? That is, preallocating memory for 200 tensors.</strong> The reason is currently I use a for loop to create 200 tensors one by one, the memory requirements just goes up very very high. Some people advised me to preallocate memory for large data structures I need before I really compute them.</p> <p>Thus, I want to preallocate an array of 200 tensors in the beginning; then in a <strong>for loop</strong> (<strong>parfor loop</strong> specifically), I compute the actual result of each tensor and send it to the preallocated space.</p> <p>Why I couldn't use:</p> <pre><code> c=repmat(tenzeros([100, 200, 300]),200,1) </code></pre> <p>which throws:</p> <pre><code>Error using tensor.size Too many output arguments. Error in repmat (line 73) [m,n] = size(A); </code></pre> <h2>----------</h2> <hr> <p>update:</p> <p><em>I pre-allocate the memory for the 200 tensors just because I heard memory preallocation can make the data continuous in the memory and thus can alleviate the OutOfMemory problem. Actually I only need each computed tensor to be written into each txt file in a for loop, which means I do not need the 200 tensors all together as my final result.</em></p> <p>So currently I am using @Andrew Janke's third piece of codes to pre-allocate the memory for the 200 tensors in the beginning:</p> <pre><code>%Memory pre-allocation c = cell([200, 1]); parfor i = 1:numel(c) c{i} = tenrand([100,200,300]); %This is just a tensor with random values to fill in the memory space end </code></pre> <p>Then I virtually compute the 200 tensors in a parfor loop and fill in the pre-allocated memory space (i.e. c):</p> <pre><code>%Compute the 200 tensors in a parfor loop parfor i = 1: 200 c{i} = computeTensorFunction(...)...; aTensor = c{i}; write aTensor (i.e. c{i}) into a text file...; end </code></pre> <ul> <li><strong>Will the second part overwrite the space in c with-preallocated memory?</strong></li> <li><strong>The experssion <code>aTensor = c{i}</code>: it doesn't make a duplicated copy, right? (I do not make changes to aTensor)</strong></li> </ul>
<p>You can preallocate a cell array of initialized <code>tensor</code> objects by using <code>repmat</code> basically the way you are, but by sticking each tensor inside a cell.</p> <pre><code>c=repmat( { tenzeros([100, 200, 300]) }, 200, 1); </code></pre> <p>The <code>{ }</code> curly braces surrounding the <code>tenzeros</code> call enclose it in a 1-by-1 cell.</p> <p>If <code>repmat</code> is blowing up, you may be able to work around it by assigning the cell contents yourself from a re-used temporary variable. This will be basically as fast as <code>repmat</code>, and have the same memory usage characteristics.</p> <pre><code>sz = [200, 1]; c = cell(sz); % Construct initial value *once* outside the loop tmp = tensor(...); for i = 1:numel(c) c{i} = tmp; end </code></pre> <p>Note that this isn't going to do as much for performance as preallocating primitive arrays, because only the top "container" level of composite types gets preallocated and possibly modified in-place. The arrays stored in fields of objects (like tensors) will still get copied when their values are changed inside functions, and probably even in the local workspace that first created them.</p> <p>This will help a little bit with the peak memory usage because all of the initial zero tensors will be sharing their memory via the copy-on-write optimization. So it's more efficient that initializing the cell array with new tensors in a loop over multiple constructor calls. But since you're going to be discarding those initial zero values anyway, the most memory-efficient way to do this would be to just initialize it with empty cells.</p> <pre><code>sz = [200, 1]; c = cell(sz); parfor i = 1:numel(c) c{i} = calculate_your_result(...); end </code></pre> <p>Because the <code>tensor</code> is a composite type (object), preallocation won't help much with the space they consume. You should probably work out an estimate of how much memory your data set will require in the best case scenario and see how that compares to the actual usage you're seeing. You might just need more memory for this application.</p>