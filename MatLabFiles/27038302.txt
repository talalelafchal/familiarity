Back propagation algorithm: error computation
<p>I am currently writing a back propagation script. I am unsure how to go about updating my weight values. Here is an image just to make things simple.</p> <p><img src="https://i.stack.imgur.com/YRATK.png" alt="enter image description here"></p> <p>My question: How is the error calculated and applied? </p> <p>I do know that k1 and k2 produce error values. I know that k1 and k2 produce individual error values (target - output). I do not however know if these are to be used. </p> <p>Am I supposed to use the mean value of both error values and then apply that single error value to all of the weights?</p> <p>Or am I supposed to: </p> <pre><code>update weight Wk1j1 and Wk1j2 with the error value of k1 update weight Wk2j1 and Wk2j2 with the error value of k2 update weight Wj1i1 and Wj1i2 with the error value of j1 update weight Wj2i1 and Wj2i2 with the error value of j2 </code></pre> <p>Before you start shooting, I understand that I must use sigmoids function etc. <em>THIS IS NOT THE QUESTION</em>. It always states that I have to calculate the error value for the outputs, this is where I am confused.</p> <p>and then get the net error value by:</p> <pre><code>((error_k1^2) + (error_k2^2) + (error_j1^2) + (error_j2^2)) / 2 </code></pre> <p>From Wiki:</p> <p><img src="https://i.stack.imgur.com/9vVKi.png" alt="enter image description here"></p> <p>As the image states this is true for each of the output nodes, in my image example k1 and k2. The wiki.</p> <p>The two rows under the image is delta Wh and delta Wi. Which error value am I supposed to use (this is basically my question, which error value am I supposed to calculate the new weight with)</p> <p><strong>Answer:</strong></p> <p><a href="http://www4.rgu.ac.uk/files/chapter3%20-%20bp.pdf" rel="nofollow noreferrer">http://www4.rgu.ac.uk/files/chapter3%20-%20bp.pdf</a> page 3(notad as 18) #4</p>
<p>Back-propagation does not use the error values directly. What you back-propagate is the <em>partial derivative</em> of the error with respect to each element of the neural network. Eventually that gives you <strong>dE/dW</strong> for each weight, and you make a small step in the direction of that gradient.</p> <p>To do this, you need to know: </p> <ul> <li><p>The activation value of each neuron (kept from when doing the feed-forward calculation)</p></li> <li><p>The mathematical form of the error function (e.g. it may be a sum of squares difference). Your first set of derivatives will be <strong>dE/da</strong> for the output layer (where <strong>E</strong> is your error and <strong>a</strong> is the output of the neuron).</p></li> <li><p>The mathematical form of the neuron activation or transfer function. This is where you discover why we use <em>sigmoid</em> because <strong>dy/dx</strong> of the sigmoid function can conveniently be expressed in terms of the activation value, <strong>dy/dx = y * (1 - y)</strong> - this is fast and also means you don't have to store or re-calculate the weighted sum.</p></li> </ul> <p><em>Please note, I am going to use different notation from you</em>, because your labels make it hard to express the general form of back-propagation.</p> <p>In my notation:</p> <ul> <li><p>Superscripts in brackets <em>(k)</em> or <em>(k+1)</em> identify a layer in the network.</p></li> <li><p>There are <em>N</em> neurons in layer <em>(k)</em>, indexed with subscript <em>i</em></p></li> <li><p>There are <em>M</em> neurons in layer <em>(k+1)</em>, indexed with subscript <em>j</em></p></li> <li><p>The sum of inputs to a neuron is <em>z</em></p></li> <li><p>The output of a neuron is <em>a</em></p></li> <li><p>A weight is <em>W<sub>ij</sub></em> and connects <em>a<sub>i</sub></em> in layer <em>(k)</em> to <em>z<sub>j</sub></em> in layer <em>(k+1)</em>. Note <em>W<sub>0j</sub></em> is the weight for bias term, and sometimes you need to include that, although your diagram does not show bias inputs or weights.</p></li> </ul> <p>With the above notation, the general form of the back-propagation algorithm is a five-step process:</p> <p>1) Calculate initial <strong>dE/da</strong> for each neuron in the output layer. Where <strong>E</strong> is your error value, and <strong>a</strong> is the activation of the neuron. This depends entirely on your error function.</p> <p>Then, for each layer (start with <em>k</em> = maximum, your output layer)</p> <p>2) Backpropagate <strong>dE/da</strong> to <strong>dE/dz</strong> for each neuron (where <strong>a</strong> is your neuron output and <strong>z</strong> is the sum of all inputs to it including the bias) within a layer. In addition to needing to know the value from (1) above, this uses the derivative of your transfer function:</p> <p><img src="https://i.stack.imgur.com/yAMZl.png" alt="enter image description here"></p> <p>(Now reduce <em>k</em> by 1 for consistency with the remainder of the loop):</p> <p>3) Backpropagate <strong>dE/dz</strong> from an upper layer to <strong>dE/da</strong> for all outputs in previous layer. This basically involves summing across all weights connecting that output neuron to the inputs in the upper layer. You don't need to do this for the input layer. Note how it uses the value you calculated in (2)</p> <p><img src="https://i.stack.imgur.com/IPIZm.png" alt="enter image description here"></p> <p>4) (Independently of (3)) Backpropagate <strong>dE/dz</strong> from an upper layer to <strong>dE/dW</strong> for all weights connecting that layer to the previous layer (this includes the bias term):</p> <p><img src="https://i.stack.imgur.com/nL96v.png" alt="enter image description here"></p> <p>Simply repeat 2 to 4 until you have <strong>dE/dW</strong> for all your weights. For more advanced networks (e.g. recurrent), you can add in other error sources by re-doing step 1.</p> <p>5) Now you have the weight derivatives, you can simply subtract them (times a learning rate) to take a step towards what you hope is the error function minimum:</p> <p><img src="https://i.stack.imgur.com/ymoYq.png" alt="enter image description here"></p> <hr> <p>The maths notation can seem a bit dense in places the first time you see this. But if you look a few times, you will see there are essentially only a few variables, and they are indexed by some combination of <em>i, j, k</em> values. In addition, with Matlab, you can express vectors and matrices really easily. So for instance this is what the whole process might look like for learning a single training example:</p> <pre class="lang-matlab prettyprint-override"><code>clear ; close all; clc; more off InputVector = [ 0.5, 0.2 ]; TrainingOutputVector = [ 0.1, 0.9 ]; learn_rate = 1.0; W_InputToHidden = randn( 3, 2 ) * 0.6; W_HiddenToOutput = randn( 3, 2 ) * 0.6; for i=1:20, % Feed-forward input to hidden layer InputsPlusBias = [1, InputVector]; HiddenActivations = 1.0 ./ (1.0 + exp(-InputsPlusBias * W_InputToHidden)); % Feed-forward hidden layer to output layer HiddenPlusBias = [ 1, HiddenActivations ]; OutputActivations = 1.0 ./ (1.0 + exp(-HiddenPlusBias * W_HiddenToOutput)); % Backprop step 1: dE/da for output layer (assumes mean square error) OutputActivationDeltas = OutputActivations - TrainingOutputVector; nn_error = sum( OutputActivationDeltas .* OutputActivationDeltas ) / 2; fprintf( 'Epoch %d, error %f\n', i, nn_error); % Steps 2 &amp; 3 combined: % Back propagate dE/da on output layer to dE/da on hidden layer % (uses sigmoid derivative) HiddenActivationDeltas = ( OutputActivationDeltas * W_HiddenToOutput(2:end,:)' .* ( HiddenActivations .* (1 - HiddenActivations) ) ); % Steps 2 &amp; 4 combined (twice): % Back propagate dE/da to dE/dW W_InputToHidden_Deltas = InputsPlusBias' * HiddenActivationDeltas; W_HiddenToOutput_Deltas = HiddenPlusBias' * OutputActivationDeltas; % Step 5: Alter the weights W_InputToHidden -= learn_rate * W_InputToHidden_Deltas; W_HiddenToOutput -= learn_rate * W_HiddenToOutput_Deltas; end; </code></pre> <p>As written this is stochastic gradient descent (weights altering once per training example), and obviously is only learning one training example.</p> <hr> <p>Apologies for pseudo-math notation in places. Stack Overflow doesn't have simple built in LaTex-like maths, unlike Math Overflow. I have skipped some of the derivation/explanation for steps 3 and 4 to avoid this answer taking forever.</p>
<p>Getting to understanding how a neural network (multilayer perceptron, specifically) does its magic can be deeply satisfying to a student of machine learning. Especially so if you can actually make one work and solve simple classification problems. Given your strong interest, you will definitely succeed.</p> <p>Once you appreciate the fact that, in order to train a neural network, you need to somehow calculate the partial derivatives of the error with respect to weights, backpropagation can be easily and qualitatively derived by reducing it to three core concepts: (1) Boxing (2) Sensitivity and (3) Weight Updates. You already have some idea that (3) is necessary.</p> <p>I agree that irritating and dense mathematical formulas ("What does this symbol mean again?") keep most students from enjoying this journey. In fact, Bernard Widrow, one of the pioneers in this area said so himself.</p> <p>In a whitepaper that I authored earlier this year (no numbered equations!), I have tried my best to devise an intuitive notation that makes it easy to connect to the concept being symbolized. Something along the lines of calling the input I, the output O, the target T etc.</p> <p>Reading this might help you with your question (and more): <a href="http://numericinsight.com/DOWNLOADS.php" rel="nofollow">A Gentle Introduction to Backpropagation.</a> This article contains pseudocode ("Training Wheels for Training Neural Networks") for implementing the algorithm.</p> <p>The pseudocode will guide you through the following easily understood steps:</p> <ol> <li>Initialize the weights and set the learning rate and the stopping criteria.</li> <li>Randomly choose an input and the corresponding target.</li> <li>Compute the input to each layer and the output of the final layer.</li> <li>Compute the sensitivity components.</li> <li>Compute the gradient components and update the weights.</li> <li>Check against the stopping criteria. Exit and return the weights or loop back to Step 2.</li> </ol>