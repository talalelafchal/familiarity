Minimizing vector or function by keeping one variable constrained
<p>I have to minimize the e f g and h by varying n within a bound between 0 to 1 and k without boundation. </p> <pre><code>% Data is as follows x = [ 1.4 15.15 49.395 98.8 151.475 184.41 230.51 259.2 ]; y = [ 12.15 21.2125 25.15125 25.3 24.63125 28.8975 29.8725 35.2 ]; % create model function q with parameters p(1) = k and p(2) = n q = @(p, x) p(1)*x.^(-p(2)); %create the desired error-functions for minimization e = @(p) sum((y.^2 - q(p, x)).^2); %// minimization function f = @(p) sum(abs(y - q(p, x))); %// better sum over absolute values g = @(p) sum(sqrt(abs(q(p, x) - y))); %// better take square roots of absolute values h = @(p) sum((q(p, x) - y).^2); %// default minimizaton function p0 = [1, -0.5]; % an initial guess [p_fit_e, r_e] = fminsearch(e, p0) % Optimize [p_fit_f, r_f] = fminsearch(f, p0) % Optimize [p_fit_g, r_g] = fminsearch(g, p0) % Optimize [p_fit_h, r_h] = fminsearch(h, p0) % Optimize </code></pre> <p>% afterwards I have another set of data of x and y and to do the same as above</p> <pre><code> x = [ 1.6 17.17 46.54 96.68 147.743 181.67 237.51 251.2 ]; y = [ 11.13 21.22 27.15125 33.3 36.125 43.5689 56.25 65.12 ]; </code></pre>