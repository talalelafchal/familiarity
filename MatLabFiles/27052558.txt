Matlab: Confusion related to Correlation operation for lags
<p>I have a time series model <code>y(t)= h^T y(t-1) + n(t)</code> where n(t) is a white Gaussian noise that excites and drives the process. <code>y</code> is the output of a linear regression model for <code>t = 1,2,...</code> denoting the number of data points.</p> <p>Question: If the Correlation matrix is <code>Ryy = E[y(t)*y(t)^T],</code> then is it possible to compute Correlation of the lagged random variables such as </p> <pre><code> [E[y(t-1)*y(t-1)']] </code></pre> <p>In general, these operators and expressions are also found in:</p> <p><a href="http://www.uio.no/studier/emner/matnat/ifi/INF4480/v10/undervisningsmateriale/spII_stocastic_processesIII_handout.pdf" rel="nofollow">Slide2</a> mentions the Autocorrelation matrix. In the formula, there is the Expectation operator. So how do I implement the expectation of the product of the lagged random variable with itself and other such expressions without using the inbuilt commands?</p> <p>I am unable to implement these kind of formulae. Please help.</p> <p>Thank you for any explanation!</p> <p>UPDATE: After doing multiple revisions to this Question, it has boiled down to another Question asked <a href="http://stackoverflow.com/questions/27113142/matlab-calculating-correlation-of-time-series">Matlab: Calculating Correlation of time series</a> . So, these two Questions have become duplicate.</p> <p>Here is a sample code</p> <pre><code>y = randn(10,1); for t = 1:10 disp(y(t)); end Expectation_y = sum(y(1:end))/10 % this give a scalar Mean_y = mean(y); % This returns 10 values </code></pre>
<p>You might be confusing the Correlation matrix of a random vector (multivariate random variable), and the autocorrelation matrix of a random process (stochastic process)...</p> <p>So if your serie is a vector autoregressive model of order 1 (which it seems to be, so <code>h'</code> is your coefficient matrix), then indeed <code>E[y(t-1)*y(t-1)']</code> makes sense, and is the Correlation matrix of the random vector itself.</p> <p>Now under the assumption of stationarity, which you can check by checking that the roots <code>x_i</code> of <code>det(I - h'*x) = 0</code> are outside the unit circle (have modulus greater than 1), then the statistical properties of <code>y[t_1]</code> are equivalent to those of <code>y[t_2]</code> for all <code>t_1, t_2</code> that are large enough. So in effect:</p> <pre><code>E[y(t-1)*y(t-1)'] = E[y(t)*y(t)'] </code></pre> <p>If your process is NOT stationary, you're in trouble, since now your correlation matrix depends on the boundary conditions of <code>t_0</code>...</p> <p>What you might be looking for, however, are expressions like:</p> <pre><code>E[y(t)*y(t-1)'] = E[(h'*y(t-1) + n(t))*y(t-1)'] </code></pre> <p>But I don't know if there are analytical representations of these in function of <code>E[y(t)*y(t)']</code>... You can research that online, or in the references that your slides provide...</p> <p><strong>EDIT:</strong></p> <p>Since the OP has mentioned that this is a simple autoregressive model and not a vector autoregressive model, things are greatly simplified.</p> <p>For stationary AR(1) models, there are nice analytical representations of the mean, variance and autocovariance (and thus autocorrelation), I'll give them here for the more general model: <code>y(t) = c + h*y(t-1) + n(t)</code></p> <pre><code>E[y(t)] = c/(1-h) --&gt; so in your case: 0 Var[y(t)] = Var[n(t)]/(1-h^2) --&gt; this is equal to the E[y(t)y(t)] or E[y(t-1)y(t-1)] that you are looking for Cov[y(t)y(t-j)] = Var[n(t)]*h^j/(1-h^2) Corr[y(t)y(t-j)] = h^j --&gt; this is the autocorrelation in function of the timedifference j </code></pre> <p>You can find all the mathematical derivations for these nicely explained in a reference book, or on the french wikipedia page: <a href="http://fr.wikipedia.org/wiki/Processus_autor%C3%A9gressif" rel="nofollow">here</a>, in the section "Moments d'un processus AR(1)"</p> <p>It really boils down now to what you are looking for... <code>E[y(t-1)y(t-1)]</code> is simply equal to <code>E[y(t)y(t)]</code> by definition of stationarity, maybe you were really looking for the derivation of <code>E[y(t)y(t-1)]</code>, which I will develop here:</p> <pre><code> E[y(t)y(t-1)] = E[(h*y(t-1) + n(t))*y(t-1)] = E[(h*y(t-1))*y(t-1)] + E[n(t)*y(t-1)] </code></pre> <p>Now since <code>n(t)</code> is the white noise in t, it is uncorrelated with y(t-1), so <code>E[n(t)*y(t-1)] = 0</code>, so we have:</p> <pre><code>E[y(t)y(t-1)] = E[(h*y(t-1))*y(t-1)] = h*E[(y(t-1))*y(t-1)] = h*Var[y(t)] = h*Var[N(t)]/(1-h^2) </code></pre> <p>Which matches exactly the definition of <code>Cov[y(t)y(t-j)]</code>given above...</p> <p>Hope this helps.</p>