Why does this work (not using vs. using optionals)?
<p>Why does alternative1 below work flawlessly?</p> <p>The macros are bogus of course and for illustration purposes only:</p> <pre><code>func commonPrefixLength&lt;T: Swift.Collection, U: Swift.Collection where T: Sequence, U: Sequence, T.GeneratorType.Element: Equatable, T.GeneratorType.Element == U.GeneratorType.Element&gt; (collection1: T, collection2: U) -&gt; T.IndexType.DistanceType { var collection2generator = collection2.generate() var i: T.IndexType.DistanceType = 0 for element1 in collection1 { #if alternative1 let element2 = collection2generator.next() if (element1 != element2) { return i } #elseif alternative2 let optionalElement2 = collection2generator.next() if let element2 = optionalElement2 { if (element1 != element2) { return i } } else { break } #endif i++ } return i } commonPrefixLength("abX", "abc") </code></pre> <p><a href="https://gist.github.com/JanX2/a62521c31e04eb741c0e" rel="nofollow">Here is a gist of the above.</a></p>
<p>In the comparison, you are comparing an optional (<code>element2</code>) with an non-optional (<code>element1</code>).</p> <pre><code>if (element1 != element2) { return i } </code></pre> <p>There is no problem comparing an optional to an non-optional. Why should there be? If <code>element2</code> is <code>nil</code>, then the result of the above comparison will be <code>true</code>. That's well defined.</p> <p>Non-optionals can be implicitly cast to optionals, otherwise you wouldn't be able to assign a non-optional to an optional.</p> <pre><code>let nonOptional = "" var optional: String? = nonOptional </code></pre>