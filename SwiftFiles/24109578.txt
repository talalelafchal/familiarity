Weird casting needed in Swift
<p>I was watching some of the videos at WWDC2014 and trying to code I liked, but one of the weird things I noticed is that Swift keeps getting mad at me and wanting me to cast to different number types. This is easy enough but in the videos at WWDC they did NOT need to do this. Here is an example from "What's New With Interface Builder":</p> <p>-M_PI/2 keeps giving me the error: "Could not find an overload for '/' that accepts the supplied arguments'</p> <p>Does anyone have a solution to this problem, that does NOT simply involve casting because there is clearly another way of doing this? I have many many more examples for similar problems to this.</p> <pre><code>if !ringLayer { ringLayer = CAShapeLayer() let innerRect = CGRectInset(bounds, lineWidth / 2.0, lineWidth / 2.0) let innerPath = UIBezierPath(ovalInRect: innerRect) ringLayer.path = innerPath.CGPath ringLayer.fillColor = nil ringLayer.lineWidth = lineWidth ringLayer.strokeColor = UIColor.blueColor().CGColor ringLayer.anchorPoint = CGPointMake(0.5, 0.5) ringLayer.transform = CATransform3DRotate (ringLayer.transform, -M_PI/2, 0, 0, 1) layer.addSublayer(ringLayer) } ringLayer.frame = layer.bounds </code></pre>
<p>There seems to be issues currently with automatic conversions between Objective C numeric types and Swift types. For this I was able to get it to work by marking the lineWidth to the Float type. I don't know why they didn't have that issue in the video, I assume that is a different build they were using. Either there is an Objective C interop setting I'm missing, or it's just a beta issue.</p> <p>To verify some of the basic issues (even happening in Playground) I used:</p> <pre><code>var x:NSNumber = 1 var y:Integer = 2 var z:Int = 3 x += 5 //error y += 6 //error z = z + y //error </code></pre>
<p><em>Edit: NB: CGFloat has changed in beta 4, specifically to make handling this 32/64-bit difference easier. Read the release notes and don't take the below as gospel now: it was written for beta 2.</em></p> <p>After a clue from <a href="http://stackoverflow.com/a/24118250/300836">this answer</a> I've worked it out: it depends on the selected project architecture. If I leave the Project architecture at the default of (armv7, arm64), then I get the same error as you with this code:</p> <pre><code> // Error with arm7 target: ringLayer.transform = CATransform3DRotate(ringLayer.transform, -M_PI/2, 0, 0, 1) </code></pre> <p>...and need to cast to a Float (well, CGFloat underneath, I'm sure) to make it work:</p> <pre><code> // Works with explicit cast on arm7 target ringLayer.transform = CATransform3DRotate(ringLayer.transform, Float(-M_PI/2), 0, 0, 1) </code></pre> <p>However, if I change the target architecture to arm64 only, then the code works as written in the Apple example from the video:</p> <pre><code> // Works fine with arm64 target: ringLayer.transform = CATransform3DRotate(ringLayer.transform, -M_PI/2, 0, 0, 1) </code></pre> <p>So to answer your question, I believe this is because CGFloat is defined as double on 64-bit architecture, so it's okay to use M_PI (which is also a double)-derived values as a CGFloat parameter. However, when arm7 is the target, CGFloat is a float, not a double, so you'd be losing precision when passing M_PI (still a double)-derived expressions directly as a CGFloat parameter.</p> <p>Note that Xcode by default will only build for the "active" architecture for Debug builds—I found it was possible to toggle this error by switching between iPhone 4S and iPhone 5S schemes in the standard drop-down in the menu bar of Xcode, as they have different architectures. I'd guess that in the demo video, there's a 64-bit architecture target selected, but in your project you've got a 32-bit architecture selected?</p> <p>Given that a CGFloat is double-precision on 64-bit architectures, the simplest way of dealing with this specific problem would be to always cast to CGFloat.</p> <p>But as a demonstration of dealing with this type of issue when you need to do different things on different architectures, Swift does support <a href="https://developer.apple.com/library/prerelease/ios/documentation/Swift/Conceptual/BuildingCocoaApps/InteractingWithCAPIs.html#//apple_ref/doc/uid/TP40014216-CH8-XID_21" rel="nofollow">conditional compilation</a>:</p> <pre><code> #if arch(x86_64) || arch(arm64) ringLayer.transform = CATransform3DRotate (ringLayer.transform, -M_PI / 2, 0, 0, 1) #else ringLayer.transform = CATransform3DRotate (ringLayer.transform, CGFloat(-M_PI / 2), 0, 0, 1) #endif </code></pre> <p>However, that's just an example. You <em>really</em> don't want to be doing this sort of thing all over the place, so I'd certainly stick to simply using <code>CGFloat(&lt;whatever POSIX double value you need&gt;)</code> to get either a 32- or 64-bit value depending on the target architecture.</p> <p>Apple have added much more help for dealing with different floats in later compiler releases—for example, in early betas you couldn't even take <code>floor()</code> of a single-precision float easily, whereas now (currently Xcode 6.1) there are overrides for <code>floor()</code>, <code>ceil()</code>, etc. for both float and double, so you don't need to be fiddling with conditional compilation.</p>
<p>For <code>Swift 1.2</code> you have to cast second parameter to <code>CGFloat</code></p> <p>This code works:</p> <pre><code>ringLayer.transform = CATransform3DRotate(ringLayer.transform, CGFloat(-M_PI/2), 0, 0, 1) </code></pre>