Perl Comparing 2 Arrays of Arrays takes too long
<p>I've developed a comparator tool in perl, that takes data from 2 CSV files and compares them according to a set of unique keys and generates an excel report. This tool works very well as long as i have 20k - 30k rows, with 10 columns per CSV file, but the time taken by the comparison algorithm rises too high, currently i'm running it for 98k rows in each CSV file and it's been running for over 4 hours now with some more time to go i think.</p> <p>The algo i'm using is:</p> <ol> <li>Loop the first array</li> <li>Grep the second array using indexes identified as unique keys with data from the first array</li> <li>Push the matched array to a new array and remove it from the original array, this way at the end i get the rows that were matched in a new array and the rows which cannot be matched stay in the original array.</li> </ol> <p>Following is my comparison code:</p> <pre><code># Actual comparison # Matched rows will go to @finalMatchedArray1 and @finalMatchedArray2 # Unmatched arrays will stay in the original arrays for ( my $j=0; $j&lt;=$#matchArray1; $j++ ) { my @result = map {$_} grep { "@{ $matchArray2[$_] }[@mapKeyArray2]" eq "@{ $matchArray1[$j] }[@mapKeyArray1]" } 0 .. $#matchArray2; if ( defined $result[0] ) { push @finalMatchedArray1,$matchArray1[$j]; push @finalMatchedArray2,$matchArray2[$result[0]]; splice ( @matchArray2,$result[0],1 ); splice ( @matchArray1,$j,1 ); $j--; } } </code></pre> <p>Following is the Data:</p> <pre><code>$matchArray1 = [[qw(a b c)], [qw(d e f)], [qw(g h i)]]; $matchArray2 = [[qw(d e f)], [qw(g k i)], [qw(a b c)]]; $mapKeyArray1 = [1,2]; $mapKeyArray2 = [1,2]; #Can be different in real example </code></pre> <p>This code works perfectly fine for less than 20k rows, i need to improve its performance in case of higher volume (98k rows in each CSV in this case)</p> <p>Please provide any pointers, code changes that might help me speed up the matching process.</p>
<p>You're searching every element of one array for every element of the other array. That's O(N<sup>2</sup>) for something that can be done in O(N).</p> <p>Generally speaking,</p> <pre><code>for my $ele_a (@a) { for my $ele_b (@b) { if (generate_key($ele_a) eq generate_key($ele_b)) { ... } } } </code></pre> <p>can be written as</p> <pre><code>my %b; for my $ele_b (@b) { $b{ generate_key($ele_b) } = $ele_b; } for my $ele_a (@a) { if (exists($b{generate_key($ele_b)}) { if (generate_key($ele_a) eq generate_key($ele_b)) { ... } } } </code></pre> <p>We can apply that here.</p> <pre><code>my @file1_key_idxs = ...; # Indexes of key fields. my @file2_key_idxs = ...; # Indexes of key fields. my @file1_data_idxs = ...; # Indexes of fields to compare. my @file2_data_idxs = ...; # Indexes of fields to compare. my @matches; # Array of [ \@keys, \@data ] my @non_matches; # Array of [ \@keys, \@file1_data, \@file2_data ] my @file1_adds; # Array of rows from file1 not in file2. my @file2_adds; # Array of rows from file2 not in file1. open(my $fh1, '&lt;:encoding(...)', ...) or die $!; open(my $fh2, '&lt;:encoding(...)', ...) or die $!; my $csv = Text::CSV_XS-&gt;new({ binary =&gt; 1 }); my %file2; while ( my $file2_row = $csv-&gt;getline($fh2) ) { my @key = @{ $file2_row }[ @file2_key_idxs ]; my $key = pack("(N/a*)*", @key; $file2{$key} = $file2_row; } </code></pre> <p>&#x20;</p> <pre><code>while ( my $file1_row = $csv-&gt;getline($fh1) ) { my @key = @{ $file1_row }[ @file1_key_idxs ]; my $key = pack("(N/a*)*", @key); if (defined(my $file2_row = $file2{$key})) { my @file1_data = @{ $file1_row }[ @file1_data_idxs ]; my $file1_data = pack("(N/a*)*", @file1_data); my @file2_data = @{ $file2_row }[ @file2_data_idxs ]; my $file2_data = pack("(N/a*)*", @file2_data); if ($file1_data eq $file2_data) { push @matches, [ \@key, \@file1_data ]; } else { push @non_matches, [ \@key, \@file1_data, \@file2_data ]; } delete $file2{$key}; } else { push @file1_adds, $file1_row; } } while (my $key = each(%file2)) { my $file2_row = delete($file2{$key}); push @file2_adds, $file2_row; } </code></pre> <p>If one of the files tends to be smaller than the other, it should be file2 to save memory and to speed things up a little.</p> <p>If memory is not a concern, the last loop can be replaced with the following to speed things up a little:</p> <pre><code>@file2_adds = values(%file2); </code></pre>
<p>Remember your time-memory tradeoff. If you can spare the memory, a hash lookup is going to be much quicker for you. C-speed as opposed to Perl-speed. </p> <p>I put the second part into a while loop, because by converting it to your purposes, you can halve the load of having two large tables in memory at the same time. </p> <p>However the problem that this solution poses is that "duplicate" lines in the same file would be eliminated. </p> <pre><code>use strict; use warnings; my ( @finalMatchedArray1, @finalMatchedArray2 ); my @matchArray1 = ( ["a","b","c"], ["d","e","f"], ["g","h","i"] ); my @matchArray2 = ( ["d","e","f"], ["g","k","i"], ["a","b","c"] ); my @mapKeyArray1 = ( 1,2 ); my @mapKeyArray2 = ( 1,2 ); my %lookup = map { ( "@{$_}[@mapKeyArray1]" =&gt; $_ ) } @matchArray1; while ( @matchArray2 ) { my $arr2 = shift @matchArray2; if ( my $arr1 = delete $lookup{ "@{$arr2}[@mapKeyArray2]" } ) { push @finalMatchedArray1, $arr1; push @finalMatchedArray2, $arr2; } } </code></pre> <p>The lack of duplicates could be handled by doing this to populate your table: </p> <pre><code>my %lookup; while ( @matchArray1 ) { my $i = shift @matchArray; push @{ $lookup{ "@{$i}[@mapKeyArray1]" } }, $i; } </code></pre> <p>And then your match process would be like so: </p> <pre><code>while ( @matchArray2 ) { if ( my $list = $lookup{ "@{$arr2}[@mapKeyArray2]" } ) { if ( @$list ) { push @finalMatchedArray1, shift @$list; push @finalMatchedArray2, $arr2; } delete $lookup{ $key } unless @$list; } } </code></pre>