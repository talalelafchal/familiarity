perl regex large data performace
<p>1.)I have a large amount of data that I read from the database (about 10million records). 2.)For each record, I search and replace about 500 regular expressions that I have. 3.) After applying all 500 regular expressions the record is then written to a file and then the next record is processed.</p> <p>The performance bottleneck is applying the 500 regular expressions on each and every record fetched from the database.</p> <p>Here is the relevant code block:</p> <pre><code>#normalizing the addresses fetched... this may take awhile while(my @row = $queryHandle-&gt;fetchrow_array()) { #extract data from record $accountKey = @row[0]; $addressLine1 = @row[1]; $addressLine2 = @row[2]; #iterate through all the regular expressions I have stored (about 500) for my $regexRef (@regexesList) { #get regular expression hash object my %regexObj = %{$regexRef}; my $regexPattern = $regexObj{pattern}; #the regex pattern my $regexOutput = $regexObj{output}; #the replacement string #first remove all special characters leaving only numbers and alphabets $addressLine1 =~ s/[^A-Za-z0-9 ]//g; $addressLine2 =~ s/[^A-Za-z0-9 ]//g; #now standardize the addresses $addressLine1 =~ s/$regexPattern/$regexOutput/ig; $addressLine2 =~ s/$regexPattern/$regexOutput/ig; } my $normalizedAddress = lc($addressLine1 . $addressLine2); $normalizedAddress =~ s/\s+//g; #remove all white space print $dataFileHandle "${normalizedAddress}\n"; $rowCount++; } </code></pre> <p>This is working code but the performance is abysmal. Currently the script has been running for 2.5hours and has written out 3.13 million records to the output file with about 7million to go haha.</p> <p>Is this the best it can get? Is there another faster, or less slower way? Maybe writing each row to a file first and then run each regular expression on the whole file?</p> <p>I would like to know if there is better way to implement this before I try the above mentioned alternative</p> <p>Thanks all!!</p>
<p>For one thing, you're doing a lot of unnecessary ref and deref. So you have a list of regexes in @regexesList, which is obviously filled with hashrefs. On each hashref as you iterate, you deref it, which makes a copy of it in memory, then you pull out items in the copied hash.</p> <p>So, first piece of advice, stop doing that. That alone abbreviates the for loop in your code to this:</p> <pre><code>for my $regexRef (@regexesList) { #first remove all special characters leaving only numbers and alphabets $addressLine1 =~ s/[^A-Za-z0-9 ]//g; $addressLine2 =~ s/[^A-Za-z0-9 ]//g; #now standardize the addresses $addressLine1 =~ s/$regexRef-&gt;{pattern}/$regexRef-&gt;{output}/ig; $addressLine2 =~ s/$regexRef-&gt;{pattern}/$regexRef-&gt;{output}/ig; } </code></pre> <p>Next, try offloading more work onto your database. When I'm using mysql for this sort of work, I offload as many simple tasks as I can to the database because these types of string functions are <em>MUCH</em> faster there. I use a lot of LOWER(), CONCAT(), CONCAT_WS(), and REPLACE(), which may also serve you here.</p>
<p>You're reparsing your 500-600 regular expressions each time, and that takes time.</p> <pre><code> $addressLine1 =~ s/$regexPattern/$regexOutput/ig; # Interpolate and reparse </code></pre> <p>The following is a proof of concept that builds an anonymous subroutine that includes your regular expressions in literal code, instead of being interpreted from variables each time.</p> <p>This demonstrates a <em>10 fold improvement</em> in performance.</p> <pre><code>use strict; use warnings; use Benchmark; my @regexesList = map {{pattern =&gt; "foo$_", output =&gt; "bar$_"}} (1..600); my $string1 = 'a' x 100; my $string2 = 'b' x 100; # Original code sub original { my ($regexesList, $addressLine1, $addressLine2) = @_; #iterate through all the regular expressions I have stored (about 500) for my $regexRef (@regexesList) { #get regular expression hash object my %regexObj = %{$regexRef}; my $regexPattern = $regexObj{pattern}; #the regex pattern my $regexOutput = $regexObj{output}; #the replacement string #now standardize the addresses $addressLine1 =~ s/$regexPattern/$regexOutput/ig; $addressLine2 =~ s/$regexPattern/$regexOutput/ig; } my $normalizedAddress = lc($addressLine1 . $addressLine2); $normalizedAddress =~ s{\s+}{}g; #remove all white space return $normalizedAddress; } # Build an anonymous subroutine to do all of the regex translations: my $regex_code = "s/\\s+//g;\n"; for (@regexesList) { $regex_code .= "s/$_-&gt;{pattern}/$_-&gt;{output}/ig;\n"; } my $code = &lt;&lt;"END_CODE"; sub { my \@address = \@_; for (\@address) { $regex_code } return lc join '', \@address; } END_CODE my $address_sub = eval $code; if ($@) { die "Invalid code $code: $@"; } # Benchmark these two calling methods: timethese(10000, { 'original' =&gt; sub { original(\@regexesList, $string1, $string2) }, 'cached' =&gt; sub { $address_sub-&gt;($string1, $string2) }, }); </code></pre> <p>Outputs:</p> <pre><code>Benchmark: timing 10000 iterations of cached, original... cached: 4 wallclock secs ( 4.23 usr + 0.00 sys = 4.23 CPU) @ 2365.74/s (n=10000) original: 47 wallclock secs (47.18 usr + 0.00 sys = 47.18 CPU) @ 211.98/s (n=10000) </code></pre> <p>Additionally, you were needlessly applying this regex <code>s/[^A-Za-z0-9 ]//g;</code> for each iteration of your loop. That was unnecessary, and could've been applied outside the loop.</p> <p>There are likely other improvements that can be made, but you'll have to utilize <a href="http://perldoc.perl.org/Benchmark.html" rel="nofollow"><code>Benchmarking</code></a> yourself to find them, as that's not really the purpose of SO.</p>