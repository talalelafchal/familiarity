Group matching lines in a text file together
<p>I have an input file:</p> <pre><code>XYZ_001 XYZ_005 XYZ_010 ABC_001 ABC_010 </code></pre> <p>I would like to groups these lines into:</p> <pre><code>XYZ,XYZ_001,XYZ_005,XYZ_010 ABC,ABC_001,ABC_010 </code></pre> <p>I have tried sorting the files and filtering out the last four characters, but I don't know how to group them together. Basically, I need to group the lines that match a regular expression together. My input file is sorted.</p> <p>My file is huge. I cannot slurp the entire file.</p>
<p>Here's a one liner to do it:</p> <pre><code>perl -ne 'chomp;if (/^([a-zA-Z]+)_/) { $hash{$1} .= ",$_"; } } END { for (keys %hash ) { print $_ . $hash{$_} . "\n" } ' input.txt </code></pre> <p>input.txt:</p> <pre><code>XYZ_001 XYZ_005 XYZ_010 ABC_001 ABC_010 </code></pre> <p>output:</p> <pre><code>ABC,ABC_001,ABC_010 XYZ,XYZ_001,XYZ_005,XYZ_010 </code></pre>
<p>You could try this sort of thing, which stores your ids and values in a hash of arrays and then iterates through them and prints:</p> <pre><code>use warnings; use strict; open my $in, '&lt;', 'in.txt'; my %data; my (@group, @n); while (&lt;$in&gt;){ chomp; my @split = split(/_/); push @group, $split[0]; push @n, $split[1]; } push @{$data{$group[$_]} }, [ $n[$_] ] for 0 .. $#group; for my $group (reverse sort keys %data){ for my $vals (@ {$data{$group} }) { my ($number) = @$vals; print "$group\_$number,"; } print "\n"; } </code></pre> <hr> <pre><code>XYZ_001,XYZ_005,XYZ_010, ABC_001,ABC_010, </code></pre>
<p>Using a perl one-liner</p> <pre><code>perl -0777 -pe 's/^([^_]+_).*\K\n(?=\1)/,/mg; s/^([^_]*)\K/,$1/mg;' file </code></pre> <p>If slurping is not an option, then this longer form logic would work:</p> <pre><code>perl -ne ' chomp; ($h) = /([^_]*)/; if ($l ne $h) {print "\n" if defined $l; $l = $h; print "$l"} print ",$_"; }{ print "\n" ' file </code></pre> <h3>Explanation:</h3> <p><strong>Switches</strong>: </p> <ul> <li><code>-0777</code>: Slurp the entire file</li> <li><code>-p</code>: Creates a <code>while(&lt;&gt;){...; print}</code> loop for each &ldquo;line&rdquo; in your input file. </li> <li><code>-e</code>: Tells <code>perl</code> to execute the code on command line. </li> </ul> <p><strong>Code</strong>:</p> <ul> <li><code>s/^([^_]+_).*\K\n(?=\1)/,/mg</code>: Group related adjacent lines: <code>XYZ_001,XYZ_005,XYZ_010</code></li> <li><code>s/^([^_]*)\K/,$1/mg</code>: Add group prefix: <code>XYZ,XYZ_001,XYZ_005,XYZ_010</code></li> </ul>
<p>perl onliner:</p> <pre><code>perl -F"_" -ane 'chomp;$s{$F[0]}.=",$_";END{ for $i (keys %s){print $i.$s{$i}."\n";} }' FILE </code></pre> <p>i use uniq hash</p>
<p>Here is how I would do this using <code>awk</code></p> <pre><code>awk -F_ '{a[$1]=(a[$1]?a[$1]","$0:$0)} END {for (i in a) print i","a[i]}' file ABC,ABC_001,ABC_010 XYZ,XYZ_001,XYZ_005,XYZ_010 </code></pre>