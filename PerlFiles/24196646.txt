Sampling intervals, not numbers, without replacement
<p>The sort of problem I am dealing with involves a few things, namely:</p> <ol> <li>I need to randomly sample numbers from a range of numbers.</li> <li>That range of numbers is really huge, as from 1 to 1,000,000,000.</li> <li>I need the sampling process to avoid sampling from intervals within the range that have already been sampled. Since using an array is too slow, my attempts to use <code>splice</code> are not going to work.</li> </ol> <p>I start by picking a number between 1 and 1,000,000,000.</p> <pre><code>my $random = int(rand(1_000_000_000)) + 1; </code></pre> <p>I add a value, say 100, to that to make <code>$random</code> and <code>$random + 100</code> define an interval. </p> <pre><code>my $interval = $random + 100; </code></pre> <p>Then I <code>push</code> both <code>$random</code> and <code>$interval</code> into another array. This other array is to store the intervals.</p> <pre><code>push ( @rememberOldIntervals, $random, $interval ); </code></pre> <p>I step through array <code>@rememberOldIntervals</code> using a <code>for</code> loop, pulling out items in pairs. The first of a pair is a former <code>$random</code> and the other a <code>$interval</code>. Inside this <code>for</code> loop, I do another random number generation. But the number generated can't be between an interval already taken. If so, keep sampling until a number is found that is unique. Further, this new random number must be at least 100 away from any old interval.</p> <pre><code>for ( my $i= 0; $i &lt; (scalar @rememberOldIntervals) / 2 ; $i=+2) { $random = int(rand(1_000_000_000)) + 1; my $new_random_low = $random - 100; my $new_random_high = $random + 100; if ( $new_random_low &lt;= $rememberOldIntervals[0] OR $new_random_high &gt;= $rememberOldIntervals[1] ){ push( @rememberOldIntervals, $new_random_low, $new_random_high ); } else { until ($new_random_low &lt;= $rememberOldIntervals[0] OR $new_random_high &gt;= $rememberOldIntervals[1] ) { $random = int(rand(1_000_000_000)) + 1; my $new_random_low = $random - 100; my $new_random_high = $random + 100; } } } </code></pre> <p>This latter loop would need to be embedded within another to drive it many times, say 10,000 times. </p>
<p>You can speed it up by using hashes and indices.</p> <p>This will part the space into indexed segments of width 200, and each interval will be placed randomly in a random segment.</p> <pre><code>my $interval = 100; my $space = 1e9; my $interval_count = 1e4; my @values; my %index_taken; for(1..$interval_count) { my $index; $index while $index_taken{$index = int rand $space/2/$interval }++; my $start = $index*2*$interval + 1 + int rand $interval; push @values, $start, $start+$interval; } </code></pre> <p>It guarantees nonoverlapping intervals but there will be inaccessible space of up to 200 between two intervals.</p> <p>Or, if you want the intervals sorted:</p> <pre><code>@values = map {$_*=2*$interval; $_+=1+int rand $interval; ($_,$_+$interval)} sort keys %index_taken; </code></pre>
<p>This problem can be reframed into pulling 10,000 random numbers between 0 and 1 billion, where no number is within 100 of another.</p> <p><strong>Brute Force</strong> - <em>5 secs</em></p> <p>Because you're only pulling 10,000 numbers, and probably don't need to do it very often, I suggest approaching this type of problem using brute force initially. This is trying to follow the design pattern of <a href="http://c2.com/cgi/wiki?PrematureOptimization" rel="nofollow"><em>Premature optimization is the root of all evil</em></a></p> <p>In this case, that means just pulling random numbers and comparing them to all previously pulled numbers. This will have a speed of <code>O(N^2)</code>, but will also take less code.</p> <pre><code>use strict; use warnings; my $max = 1_000_000_000; my $dist = 100; my $count = 10_000; die "Too many numbers" if 2 * $dist * $count &gt;= $max; my @numbers; while (@numbers &lt; $count) { my $num = int rand $max; push @numbers, $num if ! grep {abs($num - $_) &lt; $dist} @numbers; } print scalar(@numbers), "\n"; </code></pre> <p>Output takes 5 seconds:</p> <pre><code>10000 </code></pre> <p><strong>Binary Search for faster generation</strong> - <em>0.14 secs</em></p> <p>Now for faster algorithm, I agree with <code>ysth</code> that a much more efficient method to solve this is to create two lists of your random numbers. One of them is the running list, and the other is sorted. Use the sorted list to do a binary search for placement and then comparison to its nearby elements to see if it is within 100.</p> <p>This reduces the number of comparisons from <code>O(N^2)</code> to <code>O(N log N)</code>. The following takes just 0.14 seconds to run versus the 5 seconds of the brute force method.</p> <pre><code>use strict; use warnings; my $max = 1_000_000_000; my $dist = 100; my $count = 10_000; die "Too many numbers" if 2 * $dist * $count &gt;= $max; my @numbers; my @sorted = (-$dist, $max); # Include edges to simplify binary search logic. while (@numbers &lt; $count) { my $num = int rand $max; # Binary Search of Sorted list. my $binary_min = 0; my $binary_max = $#sorted; while ($binary_max &gt; $binary_min) { my $average = int( ($binary_max + $binary_min) / 2 ); $binary_max = $average if $sorted[$average] &gt;= $num; $binary_min = $average + 1 if $sorted[$average] &lt;= $num; } if (! grep {abs($num - $_) &lt; $dist} @sorted[$binary_max, $binary_max - 1]) { splice @sorted, $binary_max, 0, $num; push @numbers, $num; } } print scalar(@numbers), "\n"; </code></pre> <p><strong>Hash of quotients for fastest</strong> - <em>0.05 secs</em></p> <p>I inquired in the comments: "<em>Could you simplify this problem to pick a random multiple of 100? That would ensure no overlap, and then you'd just need to pick a random number from 1 to 10 million without repeat, and then just multiply it by 100.</em>" You didn't respond, but we can still use grouping by multiples of 100 to simplify this problem. </p> <p>Basically, if we keep track of a number's quotient divided by 100, we only need it to compare it to numbers with quotients plus and minus one. This reduces the number of comparisons to <code>O(N)</code>, which not surprisingly is the fastest at 0.05 seconds:</p> <pre><code>use strict; use warnings; my $max = 1_000_000_000; my $dist = 100; my $count = 10_000; die "Too many numbers" if 2 * $dist * $count &gt;= $max; my @numbers; my %num_per_quot; while (@numbers &lt; $count) { my $num = int rand $max; my $quotient = int $num / $dist; if (! grep {defined &amp;&amp; abs($num - $_) &lt; $dist} map {$num_per_quot{$quotient + $_}} (-1, 0, 1)) { push @numbers, $num; $num_per_quot{$quotient} = $num; } } print scalar(@numbers), "\n"; </code></pre> <p><strong><em>Caution if you're on Windows</em></strong></p> <p>If you run this code on Windows and are using a version of perl less than v5.20, you'll need to use a better random number generate than the built-in <a href="http://perldoc.perl.org/functions/rand.html" rel="nofollow"><code>rand</code></a>. For reasons why, read <a href="http://blog.nu42.com/2010/09/be-vary-of-using-built-in-rng-for.html" rel="nofollow"><code>avoid using rand if it matters</code></a>.</p> <p>I used <a href="https://metacpan.org/pod/Math%3a%3aRandom%3a%3aMT" rel="nofollow"><code>Math::Random::MT qw(rand);</code></a> in this code since I'm on Strawberry Perl v5.18.2. However, starting with Perl v5.20 this will no longer be a concern because <a href="https://metacpan.org/pod/release/RJBS/perl-5.20.0/pod/perldelta.pod#rand-now-uses-a-consistent-random-number-generator" rel="nofollow"><code>rand now uses a consistent random number generator</code></a>.</p>