R script to perl?
<p>I have an R script I want to use to parse a file and get some info out of it, but the file is 44 GB.</p> <p>Can someone help me write this in a programming language that is faster in reading files?</p> <p>The script is pretty simple:</p> <pre><code>ld &lt;- read.table("plink-inter-chr---ld-window-r2-0.ld", header = T) ldv1 &lt;- do.call(rbind, strsplit(as.character(ld[,1]), "_")) ldv4 &lt;- do.call(rbind, strsplit(as.character(ld[,4]), "_")) ld &lt;- matrix(c(ldv1[,2], ldv4[,2], ld[,2], ld[,5], ld[,7]), ncol=5) N &lt;- 30 within &lt;- numeric(N) between &lt;- numeric(N) for(i in 1:N){ within[i] &lt;- mean(as.numeric(ld[which(ld[,1] == i &amp; ld[,2] == i),5])) between[i] &lt;- mean(as.numeric(ld[which(ld[,1] == i &amp; ld[,2] != i),5])) } table &lt;- matrix(c(within, between), ncol=2) write.table(table, file = "within-between.tab", quote = FALSE, row.names = FALSE, col.names = FALSE) </code></pre> <p>And the file looks as such:</p> <pre><code> CHR_A BP_A SNP_A CHR_B BP_B SNP_B R2 DP NODE_1_length_193190_coverage_19.3759_GC_24.97 919 . NODE_1_length_193190_coverage_19.3759_GC_24.97 2210 . 1 1 NODE_1_length_193190_coverage_19.3759_GC_24.97 919 . NODE_1_length_193190_coverage_19.3759_GC_24.97 2419 . 1 1 NODE_1_length_193190_coverage_19.3759_GC_24.97 919 . NODE_1_length_193190_coverage_19.3759_GC_24.97 2524 . 1 1 NODE_1_length_193190_coverage_19.3759_GC_24.97 919 . NODE_1_length_193190_coverage_19.3759_GC_24.97 2587 . 1 1 NODE_1_length_193190_coverage_19.3759_GC_24.97 919 . NODE_1_length_193190_coverage_19.3759_GC_24.97 2799 . 1 1 NODE_1_length_193190_coverage_19.3759_GC_24.97 919 . NODE_1_length_193190_coverage_19.3759_GC_24.97 2947 . 1 1 NODE_1_length_193190_coverage_19.3759_GC_24.97 919 . NODE_1_length_193190_coverage_19.3759_GC_24.97 3142 . 1 1 NODE_1_length_193190_coverage_19.3759_GC_24.97 919 . NODE_1_length_193190_coverage_19.3759_GC_24.97 3178 . 1 1 NODE_1_length_193190_coverage_19.3759_GC_24.97 919 . NODE_1_length_193190_coverage_19.3759_GC_24.97 3261 . 1 1 </code></pre> <p>Thank you for your help, Adrian</p>
<p>Some of the places in the R code that you are wasting time and being slowed down (and therefore could speed things up quite a bit) include:</p> <p>You are reading character strings, converting them to factors, then converting them back to character strings. Look at the <code>stringsAsFactors</code> argument to <code>read.table</code> for how to avoid both conversions.</p> <p>While you are at it, you may be able to gain some speed by specifying <code>colClasses</code> in <code>read.table</code> so that the function does not need to waste time guessing what each column should be.</p> <p>After doing the string split you <code>rbind</code> everything together, but then only use 1 column from each of the resulting matrices. It may be quicker to just grab the number (or sequence of non "<em>") after the first "</em>", you can use the <code>strapply</code> function from the gsubfn package or just the <code>regexpr</code> and <code>regmatches</code> functions.</p> <p>Using the <code>cbind</code> function to create the ld matrix may be faster than concatenating then rewrapping using <code>matrix</code>. Actually, why create the matrix in the first place, you don't use 2 of the columns and the others are used separately. This also converts your numeric to character that just need to be converted back later.</p> <p>Running <code>as.numeric</code> in the loop is inefficient, you keep converting the same values over and over again, just do a single <code>as.numeric</code> on the whole matrix before the loop.</p> <p>You don't need the calls to <code>which</code> since subscripting works fine on the logicals that <code>which</code> works on.</p> <p>Fix the above and see how much that speeds up the results.</p>