How to remove lines with same domain
<p>Have large txt file of 1 million lines. Example:</p> <pre><code>http://e-planet.ru/hosting/ http://www.anelegantchaos.org/ http://site.ru/e3-den-vtoroj/ https://escrow.webmoney.ru/about.aspx http://e-planet.ru/feedback.html </code></pre> <p>How to clean it of lines with same domains?</p> <p>I need clean one of <code>http://e-planet.ru/hosting/</code> or <code>http://e-planet.ru/feedback.html</code></p>
<p>If all you care about are the domains of those URI's, then I suggest that you filter them out first.</p> <p>Then it's a simple process of sorting them and specifying you only want unique entries:</p> <pre><code>perl -lne 'print $1 if m{//(.+?)/}' file | sort | uniq &gt; uniq_domains.txt </code></pre>
<pre><code>use strict; use warnings; open my $in, '&lt;', 'in.txt' or die $!; my %seen; while(&lt;$in&gt;){ chomp; my ($domain) = /[http:|https]\/\/(.+?)\//g; $seen{$domain}++; print "$_\n" if $seen{$domain} == 1; } </code></pre>
<p>I didn't understand your question at first. Here is an awk 1-liner :</p> <pre><code>awk -F'/' '!a[$3]++' myfile </code></pre> <p>Test input : </p> <pre><code>http://e-planet.ru/hosting/ http://www.anelegantchaos.org/ http://site.ru/e3-den-vtoroj/ https://escrow.webmoney.ru/about.aspx http://e-planet.ru/feedback.html https://escrow.webmoney.ru/woopwoop httpp://whatever.com/slk </code></pre> <p>Output :</p> <pre><code>http://e-planet.ru/hosting/ http://www.anelegantchaos.org/ http://site.ru/e3-den-vtoroj/ https://escrow.webmoney.ru/about.aspx httpp://whatever.com/slk </code></pre> <p>Here, the second occurences of <code>http://e-planet.ru/</code> and <code>https://escrow.webmoney.ru/</code> are removed.</p> <p>This script splits the lines using <code>/</code> as a separator, and compares the 3rd column (the domain) to see if there are duplicates. If it is unique, it will be printed. It is to be noted that it only works if <strong>ALL</strong> urls are preceeded by <code>whateverprotocol//</code>. The double slash is important because this is what makes the 3rd column the domain</p>
<p>Sorry I'm not able to reply to fugu post,</p> <p>I think the problem might be that you have more that one URL in one line, so try this out:</p> <pre><code>use strict; use warnings; open my $in, '&lt;', 'in.txt' or die $!; my %seen; while(&lt;$in&gt;){ chomp; for (split /\s/) { my ($url) = /[http:|https]\/\/(.+?)\//g; $seen{$url}++; print "$_\n" if $seen{$url} == 1; } } </code></pre>