Change output filename from WGET when using input file option
<p>I have a perl script that I wrote that gets some image URLs, puts the urls into an input file, and proceeds to run wget with the <code>--input-file</code> option. This works perfectly... or at least it did as long as the image filenames were unique.</p> <p>I have a new company sending me data and they use a very TROUBLESOME naming scheme. All files have the same name, <code>0.jpg</code>, in different folders.</p> <p>for example: </p> <pre><code>cdn.blah.com/folder/folder/202793000/202793123/0.jpg cdn.blah.com/folder/folder/198478000/198478725/0.jpg cdn.blah.com/folder/folder/198594000/198594080/0.jpg </code></pre> <p>When I run my script with this, wget works fine and downloads all the images, but they are titled <code>0.jpg.1</code>, <code>0.jpg.2</code>, <code>0.jpg.3</code>, etc. I can't just count them and rename them because files can be broken, not available, whatever.</p> <p>I tried running wget once for each file with <code>-O</code>, but it's embarrassingly slow: starting the program, connecting to the site, downloading, and ending the program. Thousands of times. It's an hour vs minutes.</p> <p>So, I'm trying to find a method to change the output filenames from wget without it taking so long. The original approach works so well that I don't want to change it too much unless necessary, but i am open to suggestions.</p> <p>Additional:</p> <p><code>LWP::Simple</code> is too simple for this. Yes, it works, but very slowly. It has the same problem as running individual wget commands. Each <code>get()</code> or <code>get_store()</code> call makes the system re-connect to the server. Since the files are so small (60kB on average) with so many to process (1851 for this one test file alone) that the connection time is considerable.</p> <p>The filename i will be using can be found with <code>/\/(\d+)\/(\d+.jpg)/i</code> where the filename will simply be <code>$1$2</code> to get <code>2027931230.jpg</code>. Not really important for this question.</p> <p>I'm now looking at <code>LWP::UserAgent</code> with <code>LWP::ConnCache</code>, but it times out and/or hangs on my pc. I will need to adjust the timeout and retry values. The inaugural run of the code downloaded 693 images (43mb) in just a couple minutes before it hung. Using simple, I only got 200 images in 5 minutes.</p> <pre><code>use LWP::UserAgent; use LWP::ConnCache; chomp(@filelist = &lt;INPUTFILE&gt;); my $browser = LWP::UserAgent-&gt;new; $browser-&gt;conn_cache(LWP::ConnCache-&gt;new()); foreach(@filelist){ /\/(\d+)\/(\d+.jpg)/i my $newfilename = $1.$2; $response = $browser-&gt;mirror($_, $folder . $newfilename); die 'response failure' if($response-&gt;is_error()); } </code></pre>
<p><a href="https://metacpan.org/pod/LWP%3a%3aSimple" rel="nofollow">LWP::Simple</a>'s <code>getstore</code> function allows you to specify a URL to fetch from and the filename to store the data from it in. It's an excellent module for many of the same use cases as <code>wget</code>, but with the benefit of being a Perl module (i.e. no need to outsource to the shell or spawn off child processes).</p> <pre><code>use LWP::Simple; # Grab the filename from the end of the URL my $filename = (split '/', $url)[-1]; # If the file exists, increment its name while (-e $filename) { $filename =~ s{ (\d+)[.]jpg }{ $1+1 . '.jpg' }ex or die "Unexpected filename encountered"; } getstore($url, $filename); </code></pre> <p>The question doesn't specify exactly what kind of renaming scheme you need, but this will work for the examples given by simply incrementing the filename until the current directory doesn't contain that filename.</p>