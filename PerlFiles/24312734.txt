Remove duplicates from column
<p>I would like to remove duplicate lines in a file (duplicates of column 2) keeping the complete first line for each duplicate.</p> <p>Example input:</p> <pre><code>10.4.14.1,201s-1-S 10.4.16.1,201s-1-S 10.4.17.1,40-MDF-S 10.4.18.1,201s-1-S 10.4.19.1,201s-1-S 10.4.20.1,201s-1-S 10.4.21.1,201s-1-S 10.4.22.1,201s-1-S 10.4.23.1,201s-1-S 10.4.24.1,MDF-S </code></pre> <p>Desired result:</p> <pre><code>10.4.14.1,201s-1-S 10.4.17.1,40-MDF-S 10.4.24.1,MDF-S </code></pre> <p>So far I have tried</p> <pre><code>awk '!k[$5]++' file </code></pre> <p>and</p> <pre><code>awk '!_[$5]++' file </code></pre> <p>but this does not yield my desired output.</p>
<p>using a perl one-liner</p> <pre><code>perl -aF, -lne 'print if ! $seen{$F[1]}++' data.txt </code></pre> <p>Outputs:</p> <pre><code>10.4.14.1,201s-1-S 10.4.17.1,40-MDF-S 10.4.24.1,MDF-S </code></pre> <h3>Explanation:</h3> <p><strong>Switches</strong>: </p> <ul> <li><code>-a</code>: Splits the line on space and loads them in an array <code>@F</code></li> <li><code>-F/pattern/</code>: split() pattern for <code>-a</code> switch (<code>//</code>'s are optional)</li> <li><code>-l</code>: Enable line ending processing</li> <li><code>-n</code>: Creates a <code>while(&lt;&gt;){..}</code> loop for each line in your input file. </li> <li><code>-e</code>: Tells <code>perl</code> to execute the code on command line. </li> </ul>
<p>You need to set the delimiter to <code>,</code> (the default delimiter is whitespace) and use the correct column (<code>$2</code>) for the "seen" array.</p> <pre><code>$ awk -F, '!seen[$2]++' file 10.4.14.1,201s-1-S 10.4.17.1,40-MDF-S 10.4.24.1,MDF-S </code></pre>
<p>You could also use <code>sort</code> for this:</p> <pre><code>$ sort -t, -k2 -u file 10.4.14.1,201s-1-S 10.4.17.1,40-MDF-S 10.4.24.1,MDF-S </code></pre>
<p>This might work for you (GNU sed):</p> <pre><code>sed -rn '1!G;/^[^,]*(,[^\n]*)\n.*\1/!P;h' file </code></pre> <p>If the second field in the current line is not a duplicate print the current line.</p>