How to combine CSV rows based on duplicate fields using Perl Text::CSV?
<p>I would like to write a Perl script that would:</p> <ol> <li>monitor a file directory for an input CSV file on a periodic basis</li> <li>Upon file detection, open, read and merge multiple rows that have the same value for the second field/column</li> <li>Write an updated CSV file to a new directory and finally,</li> <li>Delete the input file.</li> </ol> <p>For example, I have a CSV file with information like this:</p> <pre><code>"101","5555555555","DOE, JOHN "," DOE, JOHN, your trip tomorrow from, 123 Anywhere St Apt #A, to, 100 ELSEWHERE RD APT E, is scheduled for pickup between, 1:00 PM, and 1:30 PM" "102","5555555555","DOE, JOHN "," DOE, JOHN, your trip tomorrow from, 100 ELSEWHERE RD APT E, to, 123 Anywhere St Apt #A, is scheduled for pickup between, 9:00 PM, and 9:30 PM" </code></pre> <p>I would like for the script to read, parse and detect the duplicate values for the second field ("5555555555") then create a new CSV file with the above records combined into one record as:</p> <pre><code>"101","5555555555","DOE, JOHN "," DOE, JOHN, your trip tomorrow from, 123 Anywhere St Apt #A, to, 100 ELSEWHERE RD APT E, is scheduled for pickup between, 1:00 PM, and 1:30 PM AND your trip tomorrow from, 100 ELSEWHERE RD APT E, to, 123 Anywhere St Apt #A, is scheduled for pickup between, 9:00 PM, and 9:30 PM" </code></pre> <p>My current Perl code successfully detects, reads and parses the file, however, I'm lost on how to detect the duplicates and combine the rows. </p> <pre><code>#! use strict; use warnings; use File::Find; use Text::CSV; $| = 1; use constant { #Check for CSV files only SUFFIX_LIST =&gt; qr/\.(csv)$/, DIR_TO_CHECK =&gt; "/Users/Me/Desktop/INBOUND/", }; my @file_list; while (1) { #Recursively search the input directory for CSV files find ( sub { return unless -f; return unless $_ =~ SUFFIX_LIST; #Make sure all of the files in the file list array are unique if(!(grep(/^$_$/, @file_list))) { push @file_list, $File::Find::name; } }, DIR_TO_CHECK ); #If .csv files are found... if (scalar(@file_list) &gt; 0) { print "\nNew Item in Directory\n"; parseFile($file_list[0]); #Delete input file unlink $file_list[0]; print "Deleted File\n"; #Remove the file from the file list shift @file_list; } else { print "No New Item\n"; } sleep 5; } #Subroutine to parse and compare the csv file sub parseFile() { my $csv = Text::CSV-&gt;new({ sep_char =&gt; ',', always_quote =&gt; 1, quote_char =&gt; '"', escape_char =&gt; '"', binary =&gt; 1, auto_diag =&gt; 1}); #Get the file that was passed to the function my $file = $_[0] or die "CSV file not passed in subroutine\n"; #Open file for reading open(my $data, '&lt;', $file) or die "Could not open '$file' $!\n"; while (my $line = &lt;$data&gt;) { print $line; if ($csv-&gt;parse($line)) { my @fields = $csv-&gt;fields(); } else { #warn "Line could not be parsed: $line\n"; Text::CSV-&gt;error_input(); } } close $data; } </code></pre> <p>I figure what I have is wrong for the functionality that I'm looking for because I suspect that I need to read the file as a whole into memory, instead of line by line. Please help, thanks.</p>
<p>I am not into perl this days but here is my answer. Create a hashtable with second field as key. Like this. </p> <pre><code>%hashtbl{555555} = { id =&gt; 102, # first field names =&gt; "doe, john", # third field msg =&gt; "DOE, JOHN, your trip..." # last field }; </code></pre> <p>If the key is already exists in hashtable then append its <code>msg</code></p> <pre><code>if(exists $hashtbl[$KEY]) $hashtbl{$KEY}-&gt;{msg} .= "AND $last_field" </code></pre> <p>After reading whole file, Creat a new csv file using this hashtable.</p>
<p>Something like this should work.</p> <p>It isn't perfect, but it should give a big boost. For example, you'll need to add some junk to remove the extra name in the flattened description column.</p> <pre><code>my $data = parseFile($path); flatten_record($_) for @$data; writeFile($newpath, $data); sub csv_cols { qw/ id phone name desc / ) } sub get_csv { my $csv = Text::CSV-&gt;new({ sep_char =&gt; ',', always_quote =&gt; 1, quote_char =&gt; '"', escape_char =&gt; '"', binary =&gt; 1, auto_diag =&gt; 1 }); } #Subroutine to parse csv file sub parseFile() { my ($file) = @_; die "CSV file not passed in subroutine\n" unless $file; my $csv = get_csv(); #Open file for reading open(my $fh, '&lt;', $file) or die "Could not open '$file' $!\n"; $csv-&gt;column_names( csv_cols() ); # make hash of arrays containing my %by_phone; for my $row ( @{$csv-&gt;getline_hr_all($fh)} ) { my $phone = $row-&gt;{phone} $by_phone{$phone} = [] unless $by_phone{$phone}; push @{$by_phone{$phone}}, $row; } return [ values %by_phone ]; } sub flatten_record { my ($record) = @_; die "Empty record." if @$record == 0; if ( @$record == 1 ) { $record = $record-&gt;[0]; } else { $record = { id =&gt; $record-&gt;[0]{id}, phone =&gt; $record-&gt;[0]{phone}, name =&gt; $record-&gt;[0]{name}, desc =&gt; "$record-&gt;[0]{desc} AND $record-&gt;[1]{desc}", }; } return $record; } sub writeFile { my ( $path, $data ) = @_; open my $fh, "&gt;", $path or die "Error opening '$path' for writing- $!\n"; my $csv = get_csv(); for my $record ( $data ) { my @row = @{$record}{ csv_cols() }; $csv-&gt;print( $fh, \@row ); } } </code></pre>